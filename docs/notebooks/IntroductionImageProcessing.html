<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.24">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>introductionimageprocessing – Griffin Sipes's Portfolio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-b651517ce65839d647a86e2780455cfb.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-0774fc528949661fb60d8774007a227f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Griffin Sipes’s Portfolio</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../tutorials.html"> 
<span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#interactive-introduction-to-image-processing" id="toc-interactive-introduction-to-image-processing" class="nav-link active" data-scroll-target="#interactive-introduction-to-image-processing">Interactive Introduction to Image Processing</a>
  <ul class="collapse">
  <li><a href="#why-this-matters" id="toc-why-this-matters" class="nav-link" data-scroll-target="#why-this-matters">Why this matters</a></li>
  <li><a href="#what-youll-learn" id="toc-what-youll-learn" class="nav-link" data-scroll-target="#what-youll-learn">What you’ll learn</a></li>
  <li><a href="#requirements" id="toc-requirements" class="nav-link" data-scroll-target="#requirements">Requirements</a></li>
  <li><a href="#tips-before-you-start" id="toc-tips-before-you-start" class="nav-link" data-scroll-target="#tips-before-you-start">Tips before you start</a></li>
  <li><a href="#resources-next-steps" id="toc-resources-next-steps" class="nav-link" data-scroll-target="#resources-next-steps">Resources &amp; next steps</a>
  <ul class="collapse">
  <li><a href="#environment-setup" id="toc-environment-setup" class="nav-link" data-scroll-target="#environment-setup">Environment Setup</a></li>
  <li><a href="#loading-and-displaying-images-with-opencv" id="toc-loading-and-displaying-images-with-opencv" class="nav-link" data-scroll-target="#loading-and-displaying-images-with-opencv">Loading and Displaying Images with OpenCV</a></li>
  <li><a href="#color-spaces-and-channels" id="toc-color-spaces-and-channels" class="nav-link" data-scroll-target="#color-spaces-and-channels">Color Spaces and Channels</a></li>
  <li><a href="#grayscale-imagery-why-and-how" id="toc-grayscale-imagery-why-and-how" class="nav-link" data-scroll-target="#grayscale-imagery-why-and-how">Grayscale imagery — why and how</a></li>
  <li><a href="#smoothing-blur-purpose-background-and-sharpening" id="toc-smoothing-blur-purpose-background-and-sharpening" class="nav-link" data-scroll-target="#smoothing-blur-purpose-background-and-sharpening">Smoothing / Blur — Purpose, Background, and Sharpening</a></li>
  <li><a href="#histograms-background-intuition" id="toc-histograms-background-intuition" class="nav-link" data-scroll-target="#histograms-background-intuition">Histograms — Background &amp; Intuition</a></li>
  <li><a href="#histogram-based-image-processing" id="toc-histogram-based-image-processing" class="nav-link" data-scroll-target="#histogram-based-image-processing">Histogram-based Image Processing</a></li>
  <li><a href="#binarization" id="toc-binarization" class="nav-link" data-scroll-target="#binarization">Binarization</a></li>
  <li><a href="#morphological-operations" id="toc-morphological-operations" class="nav-link" data-scroll-target="#morphological-operations">Morphological Operations</a></li>
  <li><a href="#edge-detection" id="toc-edge-detection" class="nav-link" data-scroll-target="#edge-detection">Edge Detection</a></li>
  <li><a href="#object-detection-and-face-detection" id="toc-object-detection-and-face-detection" class="nav-link" data-scroll-target="#object-detection-and-face-detection">Object Detection and Face Detection</a></li>
  <li><a href="#video-processing-object-and-face-detection-with-privacy-blurring" id="toc-video-processing-object-and-face-detection-with-privacy-blurring" class="nav-link" data-scroll-target="#video-processing-object-and-face-detection-with-privacy-blurring">Video Processing: Object and Face Detection with Privacy Blurring</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://colab.research.google.com/github/gsipes2/gsipes2.github.io/blob/main/notebooks/IntroductionImageProcessing.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid figure-img"></a></p>
<figcaption>Open in Colab</figcaption>
</figure>
</div>
<section id="interactive-introduction-to-image-processing" class="level1">
<h1>Interactive Introduction to Image Processing</h1>
<p>Welcome! This notebook is designed for beginners with no prior experience in image processing. You’ll learn how images are represented in code and get hands-on with common image transforms, filters, and detection techniques using Python.</p>
<section id="why-this-matters" class="level2">
<h2 class="anchored" data-anchor-id="why-this-matters">Why this matters</h2>
<p>Image processing is everywhere: improving medical images, cleaning up photos, extracting measurements, and powering computer vision systems such as object detectors and trackers. This notebook focuses on the practical building blocks you can reuse across projects.</p>
</section>
<section id="what-youll-learn" class="level2">
<h2 class="anchored" data-anchor-id="what-youll-learn">What you’ll learn</h2>
<ul>
<li>How images are represented (pixels, channels, color spaces)</li>
<li>Basic transforms: resizing, rotating, and cropping</li>
<li>Filters: blur, sharpen, edge detection, and morphological ops</li>
<li>How to inspect image statistics using histograms</li>
<li>How to detect objects and faces using modern libraries</li>
<li>Practical tips for tuning parameters and debugging outputs</li>
</ul>
</section>
<section id="requirements" class="level2">
<h2 class="anchored" data-anchor-id="requirements">Requirements</h2>
<p>To run this notebook, you need the following:</p>
<ul>
<li><strong>Python 3.8+</strong></li>
<li><strong>Jupyter Notebook</strong> (or JupyterLab)</li>
</ul>
</section>
<section id="tips-before-you-start" class="level2">
<h2 class="anchored" data-anchor-id="tips-before-you-start">Tips before you start</h2>
<ul>
<li>Run cells sequentially so variables (like <code>img</code>) are available.</li>
<li>If an example is slow, reduce sizes (resize to 320x240) for faster iteration.</li>
<li>Use the provided <code>test_image.jpg</code> or change the filename to your own image.</li>
</ul>
</section>
<section id="resources-next-steps" class="level2">
<h2 class="anchored" data-anchor-id="resources-next-steps">Resources &amp; next steps</h2>
<ul>
<li>OpenCV documentation: https://docs.opencv.org/</li>
<li>Ultralytics (YOLO) docs: https://docs.ultralytics.com/</li>
<li>MediaPipe face detection: https://developers.google.com/mediapipe</li>
</ul>
<section id="environment-setup" class="level3">
<h3 class="anchored" data-anchor-id="environment-setup">Environment Setup</h3>
<p>This cell sets up the environment for image and video processing. It downloads and imports essential libraries:</p>
<ul>
<li><code>os</code> for file operations.</li>
<li><code>cv2</code> (OpenCV) for image and video processing.</li>
<li><code>numpy</code> for numerical operations.</li>
<li><code>matplotlib.pyplot</code> for plotting images and results.</li>
</ul>
<p>It also defines file paths for the test image, video, and YOLO model, and prints quick checks to confirm that these files exist and that OpenCV is installed. This ensures all required resources are available before running further image processing tasks.</p>
<div id="57502eeb" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install required packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install opencv<span class="op">-</span>python matplotlib numpy ultralytics mediapipe ipython</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Direct download links for Box files</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>IMG_URL <span class="op">=</span> <span class="st">'https://uofi.box.com/shared/static/4vwmy8d4zutugdq54xj0jm98y2dsv8t0.jpg'</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>VIDEO_URL <span class="op">=</span> <span class="st">'https://uofi.box.com/shared/static/of08em0yjvobx6xoqtxzk02glq9d8e55.mp4'</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>YOLO_URL <span class="op">=</span> <span class="st">'https://uofi.box.com/shared/static/pma36x7cge58b3i18b2o0xqlcqd38iwk.pt'</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> download_file(url, save_path):</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> requests.get(url, stream<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    r.raise_for_status()</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(save_path, <span class="st">'wb'</span>) <span class="im">as</span> f:</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> chunk <span class="kw">in</span> r.iter_content(chunk_size<span class="op">=</span><span class="dv">8192</span>):</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            f.write(chunk)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> save_path</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Download files to /content/</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">'/content/test_image.jpg'</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>video_path <span class="op">=</span> <span class="st">'/content/GX010881.MP4'</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>yolo_path <span class="op">=</span> <span class="st">'/content/yolo11n.pt'</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>download_file(IMG_URL, img_path)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>download_file(VIDEO_URL, video_path)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>download_file(YOLO_URL, yolo_path)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Load image</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> cv2.imread(img_path)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Image loaded:'</span>, img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Load video</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>video <span class="op">=</span> cv2.VideoCapture(video_path)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Video loaded:'</span>, video.isOpened())</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Check YOLO model file</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'YOLO model downloaded:'</span>, os.path.exists(yolo_path))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>cv2 version: 4.11.0
img exists: True
video exists: True
model file exists: True</code></pre>
</div>
</div>
</section>
<section id="loading-and-displaying-images-with-opencv" class="level3">
<h3 class="anchored" data-anchor-id="loading-and-displaying-images-with-opencv">Loading and Displaying Images with OpenCV</h3>
<p>OpenCV is a powerful library for image processing in Python. To get started, you need to load an image from disk and display it. Here’s how:</p>
<section id="loading-an-image" class="level4">
<h4 class="anchored" data-anchor-id="loading-an-image">Loading an Image</h4>
<p>Use <code>cv2.imread()</code> to load an image from a file. The image is read as a NumPy array in BGR (Blue, Green, Red) format.</p>
<div id="e450bf67" class="cell" data-execution_count="129">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Load and Display an Image</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load an image from file</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> cv2.imread(<span class="st">'test_image.jpg'</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    img_rgb <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  <span class="co"># Convert BGR to RGB</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img_rgb)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Loaded Image'</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not found. Try changing the filename to an image file.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="color-spaces-and-channels" class="level3">
<h3 class="anchored" data-anchor-id="color-spaces-and-channels">Color Spaces and Channels</h3>
<p>Images are made up of pixels, and each pixel can have one or more <strong>channels</strong> depending on the color space used. Understanding color spaces and channels is essential for effective image analysis and processing.</p>
<section id="what-is-a-color-space" class="level4">
<h4 class="anchored" data-anchor-id="what-is-a-color-space">What is a Color Space?</h4>
<p>A <strong>color space</strong> is a specific way of representing colors numerically. It defines how pixel values map to actual colors. Common color spaces include RGB, LAB, and HSV.</p>
</section>
<section id="what-is-a-channel" class="level4">
<h4 class="anchored" data-anchor-id="what-is-a-channel">What is a Channel?</h4>
<p>A <strong>channel</strong> is a single component of a color space. For example, in RGB, each pixel has three channels: Red, Green, and Blue. In grayscale images, there is only one channel representing intensity.</p>
</section>
<section id="common-color-spaces" class="level4">
<h4 class="anchored" data-anchor-id="common-color-spaces">Common Color Spaces</h4>
<ul>
<li><strong>RGB (Red, Green, Blue):</strong>
<ul>
<li>Each pixel has three channels: R, G, and B.</li>
<li>Used for display and general image processing.</li>
<li>Not perceptually uniform.</li>
</ul></li>
<li>**LAB (L<em>a</em>b*):**
<ul>
<li>Three channels: L (lightness), a (green–red), b (blue–yellow).</li>
<li>Designed for perceptual uniformity.</li>
<li>Useful for color correction and measuring color differences.</li>
</ul></li>
<li><strong>HSV (Hue, Saturation, Value):</strong>
<ul>
<li>Three channels: H (hue), S (saturation), V (value/brightness).</li>
<li>Separates color information (hue) from intensity (value).</li>
<li>Useful for color-based segmentation and filtering.</li>
</ul></li>
</ul>
</section>
<section id="why-channels-matter" class="level4">
<h4 class="anchored" data-anchor-id="why-channels-matter">Why Channels Matter</h4>
<ul>
<li><strong>Channel manipulation:</strong> You can process each channel separately (e.g., enhance brightness, isolate colors).</li>
<li><strong>Visualization:</strong> Viewing individual channels helps understand image structure and color distribution.</li>
<li><strong>Analysis:</strong> Some algorithms work better on specific channels (e.g., edge detection on intensity, segmentation on hue).</li>
</ul>
<p><strong>Tip:</strong><br>
Choose the color space and channels that best fit your task. For example, use LAB for brightness/contrast adjustment, HSV for color segmentation, and RGB for visualization.</p>
<div id="a3dcc42b" class="cell" data-execution_count="133">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show original image and individual color channels (RGB, LAB, HSV)</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># RGB channels</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    img_rgb <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    r, g, b <span class="op">=</span> img_rgb[:, :, <span class="dv">0</span>], img_rgb[:, :, <span class="dv">1</span>], img_rgb[:, :, <span class="dv">2</span>]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LAB channels</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    lab <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2LAB)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    l_lab, a_lab, b_lab <span class="op">=</span> cv2.split(lab)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># HSV channels</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    hsv <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2HSV)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    h_hsv, s_hsv, v_hsv <span class="op">=</span> cv2.split(hsv)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Row 1: RGB</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">1</span>)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img_rgb)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'RGB (original)'</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    plt.imshow(r, cmap<span class="op">=</span><span class="st">'Reds'</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Red channel'</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">3</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    plt.imshow(g, cmap<span class="op">=</span><span class="st">'Greens'</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Green channel'</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    plt.imshow(b, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Blue channel'</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Row 2: LAB</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    plt.imshow(l_lab, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'LAB L (Lightness)'</span>)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">6</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    plt.imshow(a_lab, cmap<span class="op">=</span><span class="st">'RdYlGn'</span>)</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'LAB a (Green-Red)'</span>)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">7</span>)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    plt.imshow(b_lab, cmap<span class="op">=</span><span class="st">'RdYlBu'</span>)</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'LAB b (Blue-Yellow)'</span>)</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">8</span>)</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)  <span class="co"># Empty for layout</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Row 3: HSV</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">9</span>)</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    plt.imshow(h_hsv, cmap<span class="op">=</span><span class="st">'hsv'</span>)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'HSV H (Hue)'</span>)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">10</span>)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    plt.imshow(s_hsv, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'HSV S (Saturation)'</span>)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">11</span>)</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    plt.imshow(v_hsv, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'HSV V (Value)'</span>)</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">12</span>)</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)  <span class="co"># Empty for layout</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="grayscale-imagery-why-and-how" class="level3">
<h3 class="anchored" data-anchor-id="grayscale-imagery-why-and-how">Grayscale imagery — why and how</h3>
<p>Grayscale images use a single intensity channel, making them faster to process and easier for many algorithms (e.g., edge detection, thresholding). Converting to grayscale is a common first step in image analysis.</p>
<section id="background" class="level4">
<h4 class="anchored" data-anchor-id="background">Background</h4>
<p>Most digital images are captured in color, with each pixel containing multiple values (channels) for red, green, and blue. However, many image processing tasks—such as measuring brightness, detecting edges, or segmenting objects—work best on simpler data. Grayscale images reduce complexity by representing each pixel with a single value for intensity, ranging from black (0) to white (255).</p>
<p>Grayscale conversion is widely used in medical imaging, document analysis, and computer vision because it: - Removes color distractions, focusing on structure and contrast. - Speeds up processing and reduces memory usage. - Simplifies algorithms that rely on intensity rather than color.</p>
<p><strong>Tip:</strong><br>
Start with grayscale for tasks like thresholding, edge detection, and morphological operations. Use color only when necessary for segmentation or visualization.</p>
<div id="7ed78665" class="cell" data-execution_count="87">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the loaded image to grayscale and display it</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    gray <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    plt.imshow(gray, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Grayscale Image'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="image-resizing-and-rotation" class="level4">
<h4 class="anchored" data-anchor-id="image-resizing-and-rotation">Image Resizing and Rotation</h4>
<p>Resizing and rotating images are essential preprocessing steps in image analysis and computer vision.</p>
<p><strong>Why resize?</strong><br>
- Reduces memory and computation time, especially for large images or real-time applications. - Enables faster experimentation and model training. - Helps standardize input sizes for neural networks and algorithms.</p>
<p><strong>Why rotate?</strong><br>
- Corrects image orientation for consistent analysis. - Useful for aligning features or objects in medical, satellite, or document images.</p>
<p><strong>Tip:</strong><br>
When enlarging images, use interpolation methods (e.g., bilinear, bicubic) to avoid pixelation and preserve quality. For shrinking, simple nearest-neighbor or area interpolation is often sufficient.</p>
<p>Resizing and rotating are quick ways to optimize your workflow and improve downstream results.</p>
<div id="4f13dd0d" class="cell" data-execution_count="135">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Resize and rotate examples</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Use the grayscale image 'gray' if available, otherwise convert</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    small <span class="op">=</span> cv2.resize(gray, (<span class="dv">320</span>, <span class="dv">240</span>))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    rotated <span class="op">=</span> cv2.rotate(small, cv2.ROTATE_90_CLOCKWISE)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    plt.imshow(small, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Resized (320x240)'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    plt.imshow(rotated, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Rotated 90 deg'</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="smoothing-blur-purpose-background-and-sharpening" class="level3">
<h3 class="anchored" data-anchor-id="smoothing-blur-purpose-background-and-sharpening">Smoothing / Blur — Purpose, Background, and Sharpening</h3>
<p>Blurring (smoothing) is a fundamental image processing technique that reduces high-frequency noise and small details. It is commonly used before edge detection, thresholding, or segmentation to suppress speckle and minor artifacts, making features easier to analyze.</p>
<section id="why-blur" class="level4">
<h4 class="anchored" data-anchor-id="why-blur">Why Blur?</h4>
<ul>
<li><strong>Noise reduction:</strong> Removes random pixel fluctuations and small unwanted details.</li>
<li><strong>Preprocessing:</strong> Improves the reliability of subsequent steps like edge detection and binarization.</li>
<li><strong>Visual effect:</strong> Produces a softer, less detailed image.</li>
</ul>
<p>A <strong>Gaussian blur</strong> uses a weighted kernel (must be odd-sized, e.g., 3x3, 5x5, 11x11) to average pixel values, giving more weight to the center. Larger kernels produce stronger smoothing.</p>
</section>
<section id="sharpening" class="level4">
<h4 class="anchored" data-anchor-id="sharpening">Sharpening</h4>
<p>Sharpening enhances edges and fine details, making features stand out. It is often used after blurring or on its own to improve image clarity.</p>
<ul>
<li><strong>How it works:</strong> Sharpening applies a kernel that emphasizes differences between neighboring pixels, boosting contrast at edges.</li>
<li><strong>Common method:</strong> The Laplacian or unsharp mask filter.</li>
</ul>
<p><strong>Tip:</strong><br>
Use blurring to clean up noise before analysis. Use sharpening to highlight boundaries and details for visualization or feature extraction.</p>
<p><strong>Example kernels:</strong> - Gaussian blur:<br>
<code>[[1, 2, 1],      [2, 4, 2],      [1, 2, 1]] / 16</code> - Sharpening:<br>
<code>[[ 0, -1,  0],      [-1,  5, -1],      [ 0, -1,  0]]</code></p>
<div id="1ee2967f" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    plt.imshow(gray, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Original Grayscale'</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gaussian blur with 11x11 kernel and sigma=0</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    blurred <span class="op">=</span> cv2.GaussianBlur(gray, (<span class="dv">11</span>, <span class="dv">11</span>), <span class="dv">0</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    plt.imshow(blurred, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Blurred (Gaussian)'</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sharpening kernel</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    sharpen_kernel <span class="op">=</span> np.array([[<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>],</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>                               [<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="op">-</span><span class="dv">1</span>],</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>                               [<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>]])</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    sharpened <span class="op">=</span> cv2.filter2D(gray, <span class="op">-</span><span class="dv">1</span>, sharpen_kernel)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    plt.imshow(sharpened, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Sharpened'</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="histograms-background-intuition" class="level3">
<h3 class="anchored" data-anchor-id="histograms-background-intuition">Histograms — Background &amp; Intuition</h3>
<p>An <strong>image histogram</strong> is a graphical representation of the distribution of pixel intensities (brightness or color values) in an image. It helps you understand the overall exposure, contrast, and color balance at a glance.</p>
<section id="what-does-a-histogram-show" class="level4">
<h4 class="anchored" data-anchor-id="what-does-a-histogram-show">What does a histogram show?</h4>
<ul>
<li><strong>X-axis:</strong> Pixel intensity values (0–255 for 8-bit images).</li>
<li><strong>Y-axis:</strong> Number of pixels at each intensity.</li>
<li><strong>Grayscale images:</strong> One histogram for brightness.</li>
<li><strong>Color images:</strong> Separate histograms for each channel (Red, Green, Blue).</li>
</ul>
</section>
<section id="why-are-histograms-useful" class="level4">
<h4 class="anchored" data-anchor-id="why-are-histograms-useful">Why are histograms useful?</h4>
<ul>
<li><strong>Contrast:</strong> A wide histogram means high contrast; a narrow one means low contrast.</li>
<li><strong>Brightness:</strong> If the histogram is shifted left, the image is dark; shifted right, it’s bright.</li>
<li><strong>Exposure:</strong> Peaks at the ends may indicate underexposure (too dark) or overexposure (too bright).</li>
<li><strong>Color balance:</strong> Comparing channel histograms reveals color casts or imbalances.</li>
</ul>
</section>
<section id="practical-uses" class="level4">
<h4 class="anchored" data-anchor-id="practical-uses">Practical uses</h4>
<ul>
<li><strong>Image enhancement:</strong> Adjust brightness/contrast or apply histogram equalization.</li>
<li><strong>Thresholding:</strong> Choose thresholds for binarization based on histogram shape.</li>
<li><strong>Quality control:</strong> Detect poor lighting or exposure problems.</li>
</ul>
<p>Histograms are a simple but powerful tool for diagnosing and improving images in any image processing workflow.</p>
<div id="b381c040" class="cell" data-execution_count="127">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Intensity and channel histograms</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    plt.hist(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).ravel(), bins<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Intensity histogram'</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    plt.hist(r.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Red hist'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    plt.hist(g.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'g'</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Green hist'</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="histogram-based-image-processing" class="level3">
<h3 class="anchored" data-anchor-id="histogram-based-image-processing">Histogram-based Image Processing</h3>
<p>Histogram-based image processing uses the distribution of pixel intensities to analyze and enhance images. By examining the histogram, we can adjust brightness, contrast, and exposure, detect features, and segment regions. This approach is essential because it provides a quantitative way to understand image quality and apply targeted corrections, making images more useful for visualization and further analysis.</p>
<p><strong>CLAHE (Contrast Limited Adaptive Histogram Equalization)</strong> is an advanced method for improving image contrast, especially in images with varying lighting or local features. Unlike standard histogram equalization, which adjusts contrast globally, CLAHE works on small regions (tiles) of the image and limits amplification to avoid noise.</p>
<section id="standard-histogram-equalization" class="level4">
<h4 class="anchored" data-anchor-id="standard-histogram-equalization">Standard Histogram Equalization</h4>
<ul>
<li><strong>Global adjustment:</strong> Redistributes pixel intensities across the entire image.</li>
<li><strong>Best for:</strong> Images with uniform lighting and global low contrast.</li>
<li><strong>Drawbacks:</strong> Can over-amplify noise and create unnatural effects in areas with little variation.</li>
</ul>
</section>
<section id="clahe" class="level4">
<h4 class="anchored" data-anchor-id="clahe">CLAHE</h4>
<ul>
<li><strong>Local adjustment:</strong> Applies histogram equalization to small tiles, then combines them.</li>
<li><strong>Contrast limiting:</strong> Prevents over-amplification of noise by clipping the histogram.</li>
<li><strong>Best for:</strong> Medical images, uneven lighting, or images with both bright and dark regions.</li>
<li><strong>Advantages:</strong> Preserves local details, avoids noise amplification, and produces more natural results.</li>
</ul>
<p><strong>Summary:</strong><br>
Use standard histogram equalization for quick global contrast enhancement. Use CLAHE for images with local contrast issues, uneven illumination, or when you want to avoid boosting noise.</p>
<div id="57e99c92" class="cell" data-execution_count="126">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram equalization and CLAHE comparison (grayscale, LAB luminance)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prepare processed images</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    gray_eq <span class="op">=</span> cv2.equalizeHist(gray)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    gray_clahe <span class="op">=</span> cv2.createCLAHE(clipLimit<span class="op">=</span><span class="fl">2.0</span>, tileGridSize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    img_clahe <span class="op">=</span> gray_clahe.<span class="bu">apply</span>(gray)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    lab <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2LAB)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    l, a, b <span class="op">=</span> cv2.split(lab)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    l_eq <span class="op">=</span> cv2.equalizeHist(l)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    lab_eq <span class="op">=</span> cv2.merge((l_eq, a, b))</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    lab_eq_rgb <span class="op">=</span> cv2.cvtColor(lab_eq, cv2.COLOR_LAB2RGB)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    l_clahe <span class="op">=</span> gray_clahe.<span class="bu">apply</span>(l)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    lab_clahe <span class="op">=</span> cv2.merge((l_clahe, a, b))</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    lab_clahe_rgb <span class="op">=</span> cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2RGB)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Figure 1: Images (2 rows x 3 cols)</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">8</span>))</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    plt.imshow(gray, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Original Grayscale'</span>)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>    plt.imshow(gray_eq, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Histogram Equalized'</span>)</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img_clahe, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'CLAHE Grayscale'</span>)</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img_rgb)</span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Original Color (RGB)'</span>)</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>    plt.imshow(lab_eq_rgb)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Histogram Equalized LAB Luminance'</span>)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">6</span>)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    plt.imshow(lab_clahe_rgb)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'CLAHE LAB Luminance'</span>)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Figure 2: Histograms corresponding to the images (2 rows x 3 cols)</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">8</span>))</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>    plt.hist(gray.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Original Grayscale Hist'</span>)</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    plt.hist(gray_eq.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Hist Eq Grayscale Hist'</span>)</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>    plt.hist(img_clahe.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'CLAHE Grayscale Hist'</span>)</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>    <span class="co"># histogram for original LAB luminance channel</span></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>    plt.hist(l.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'gray'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Luminance'</span>)</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Original LAB Luminance Hist'</span>)</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>    plt.ylim(<span class="dv">0</span>, <span class="dv">30000</span>)</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>    plt.hist(l_eq.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'purple'</span>)</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Histogram Equalized LAB Luminance'</span>)</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">6</span>)</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    plt.hist(l_clahe.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'CLAHE Lab Luminance'</span>)</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-9-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-9-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="binarization" class="level3">
<h3 class="anchored" data-anchor-id="binarization">Binarization</h3>
<p><strong>Binarization</strong> is the process of converting a grayscale image into a binary image, where each pixel is either black (0) or white (255). This is done by applying a threshold: pixels above the threshold become white, and those below become black.</p>
<section id="why-use-binarization" class="level4">
<h4 class="anchored" data-anchor-id="why-use-binarization">Why Use Binarization?</h4>
<ul>
<li><strong>Simplifies analysis:</strong> Many image processing tasks (like shape analysis, object counting, and OCR) work better on binary images.</li>
<li><strong>Separates foreground from background:</strong> Useful for segmenting objects from their surroundings.</li>
<li><strong>Preprocessing for algorithms:</strong> Many algorithms (e.g., contour detection, morphological operations) require binary input.</li>
</ul>
</section>
<section id="how-does-binarization-work" class="level4">
<h4 class="anchored" data-anchor-id="how-does-binarization-work">How Does Binarization Work?</h4>
<ol type="1">
<li><strong>Choose a threshold value</strong> (e.g., 100).</li>
<li><strong>Compare each pixel’s intensity</strong> to the threshold.
<ul>
<li>If the pixel value &gt; threshold, set it to 255 (white).</li>
<li>If the pixel value ≤ threshold, set it to 0 (black).</li>
</ul></li>
</ol>
</section>
<section id="otsus-method-automatic-threshold-selection" class="level4">
<h4 class="anchored" data-anchor-id="otsus-method-automatic-threshold-selection">Otsu’s Method — Automatic Threshold Selection</h4>
<p><strong>Otsu’s method</strong> is a popular technique for automatically finding the optimal threshold value. It works by: - Analyzing the histogram of pixel intensities. - Finding the threshold that minimizes the variance within each class (foreground and background), or equivalently, maximizes the separation between them.</p>
<p><strong>Advantages:</strong> - No manual tuning needed. - Works well when the image has a clear bimodal histogram (two peaks: one for background, one for foreground).</p>
<p><strong>In practice:</strong><br>
Otsu’s method is widely used for document scanning, medical imaging, and any scenario where robust, automatic binarization is needed.</p>
<div id="269514ab" class="cell" data-execution_count="100">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show histogram</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">4</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    plt.hist(gray.ravel(), bins<span class="op">=</span><span class="dv">256</span>, color<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Grayscale Histogram'</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Pixel Intensity'</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Otsu's thresholding</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    otsu_thresh, binary_img <span class="op">=</span> cv2.threshold(</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        gray, <span class="dv">0</span>, <span class="dv">255</span>, cv2.THRESH_BINARY <span class="op">+</span> cv2.THRESH_OTSU)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    plt.axvline(otsu_thresh, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'dashed'</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>                label<span class="op">=</span><span class="ss">f'Otsu Threshold = </span><span class="sc">{</span>otsu_thresh<span class="sc">:.0f}</span><span class="ss">'</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Show binarized image</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    plt.imshow(binary_img, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Binarized Image (Otsu Threshold)'</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-10-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="morphological-operations" class="level3">
<h3 class="anchored" data-anchor-id="morphological-operations">Morphological Operations</h3>
<p><strong>Morphological operations</strong> are image processing techniques that probe and modify the shapes of objects in binary or grayscale images. The two most common operations are <strong>erosion</strong> and <strong>dilation</strong>.</p>
<section id="what-is-erosion" class="level4">
<h4 class="anchored" data-anchor-id="what-is-erosion">What is Erosion?</h4>
<ul>
<li><strong>Purpose:</strong> Erosion shrinks bright regions and removes small white noise. It is useful for eliminating tiny artifacts, separating objects that are close together, and reducing the size of foreground objects.</li>
<li><strong>How it works:</strong> Erosion slides a small shape (called a <em>structuring element</em> or <em>kernel</em>) over the image. At each position, if <em>all</em> pixels under the kernel are bright (e.g., white in binary images), the output pixel remains bright; otherwise, it becomes dark. This causes boundaries of bright regions to shrink.</li>
</ul>
</section>
<section id="what-is-dilation" class="level4">
<h4 class="anchored" data-anchor-id="what-is-dilation">What is Dilation?</h4>
<ul>
<li><strong>Purpose:</strong> Dilation expands bright regions and fills small holes or gaps. It is useful for joining broken parts of objects, making features thicker, and connecting nearby objects.</li>
<li><strong>How it works:</strong> Dilation also slides a kernel over the image. At each position, if <em>any</em> pixel under the kernel is bright, the output pixel becomes bright. This causes boundaries of bright regions to grow outward.</li>
</ul>
</section>
<section id="practical-use" class="level4">
<h4 class="anchored" data-anchor-id="practical-use">Practical Use</h4>
<ul>
<li><strong>Noise removal:</strong> Erosion followed by dilation (called <em>opening</em>) removes small noise while preserving object shape.</li>
<li><strong>Object joining:</strong> Dilation followed by erosion (called <em>closing</em>) fills small holes and connects nearby objects.</li>
<li><strong>Parameter tuning:</strong> The size and shape of the kernel control the strength and direction of the effect. Larger kernels produce stronger changes.</li>
</ul>
<p><strong>Tip:</strong> Try different kernel sizes and shapes to see how they affect your image. Use erosion to clean up noise, and dilation to restore or connect features.</p>
<div id="50c828b4" class="cell" data-execution_count="105">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Erosion and dilation on binarized image</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">4</span>))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    plt.imshow(binary_img, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Original Binary'</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 15x15 kernel for demo. Adjust size as needed.</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    kernel <span class="op">=</span> cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="dv">3</span>, <span class="dv">3</span>))</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    eroded_bin <span class="op">=</span> cv2.erode(binary_img, kernel, iterations<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    dilated_bin <span class="op">=</span> cv2.dilate(binary_img, kernel, iterations<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    plt.imshow(eroded_bin, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Erosion (15x15)'</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    plt.imshow(dilated_bin, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Dilation (15x15)'</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="edge-detection" class="level3">
<h3 class="anchored" data-anchor-id="edge-detection">Edge Detection</h3>
<p>Edge detection is a fundamental technique in image processing and computer vision. <strong>Edges</strong> represent boundaries where pixel intensities change sharply, often corresponding to object outlines, texture changes, or surface discontinuities.</p>
<section id="why-detect-edges" class="level4">
<h4 class="anchored" data-anchor-id="why-detect-edges">Why Detect Edges?</h4>
<ul>
<li><strong>Object boundaries:</strong> Edges help segment objects from the background.</li>
<li><strong>Feature extraction:</strong> Many algorithms use edges to identify shapes, corners, and regions of interest.</li>
<li><strong>Image understanding:</strong> Edges simplify images, making it easier to analyze and interpret content.</li>
</ul>
</section>
<section id="how-does-edge-detection-work" class="level4">
<h4 class="anchored" data-anchor-id="how-does-edge-detection-work">How Does Edge Detection Work?</h4>
<p>Edge detectors analyze local intensity changes in an image. They highlight pixels where the difference between neighboring values is large. Common approaches include: - <strong>Gradient-based methods:</strong> Compute the rate of change (gradient) in intensity. Examples: Sobel, Prewitt, Roberts. - <strong>Canny edge detector:</strong> A multi-stage algorithm that smooths the image, finds gradients, applies non-maximum suppression, and uses double thresholding to select strong and weak edges.</p>
</section>
<section id="canny-edge-detector" class="level4">
<h4 class="anchored" data-anchor-id="canny-edge-detector">Canny Edge Detector</h4>
<p>The Canny method is popular because it produces clean, thin edges and reduces noise. It uses two thresholds: - <strong>Low threshold:</strong> Detects weak edges. - <strong>High threshold:</strong> Detects strong edges. Edges connected to strong edges are kept; isolated weak edges are discarded.</p>
<p><strong>Tip:</strong> Adjust thresholds to control edge sensitivity. Lower values reveal more edges (including noise); higher values show only the most prominent boundaries.</p>
<p>Edge detection is a key step for tasks like segmentation, tracking, and recognition.</p>
<div id="ef09e292" class="cell" data-execution_count="136">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare Sobel gradient (simpler) with Canny edge detection (more complex)</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sobel gradient (X and Y)</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    sobelx <span class="op">=</span> cv2.Sobel(gray, cv2.CV_64F, <span class="dv">1</span>, <span class="dv">0</span>, ksize<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    sobely <span class="op">=</span> cv2.Sobel(gray, cv2.CV_64F, <span class="dv">0</span>, <span class="dv">1</span>, ksize<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    sobel_mag <span class="op">=</span> cv2.magnitude(sobelx, sobely)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    sobel_mag <span class="op">=</span> cv2.convertScaleAbs(sobel_mag)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Canny edge detection</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    edges_canny <span class="op">=</span> cv2.Canny(gray, <span class="dv">200</span>, <span class="dv">400</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    plt.imshow(sobel_mag, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Sobel Gradient Magnitude'</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    plt.imshow(edges_canny, cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Canny Edge Detection'</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="object-detection-and-face-detection" class="level3">
<h3 class="anchored" data-anchor-id="object-detection-and-face-detection">Object Detection and Face Detection</h3>
<p>Modern image processing leverages deep learning models to automatically detect and localize objects and faces in images and videos. Two popular approaches are <strong>YOLO (You Only Look Once)</strong> for general object detection and <strong>MediaPipe Face Detection</strong> for fast, lightweight face localization.</p>
<section id="yolo-object-detection" class="level4">
<h4 class="anchored" data-anchor-id="yolo-object-detection">YOLO Object Detection</h4>
<ul>
<li><strong>YOLO</strong> is a family of real-time object detectors that predict bounding boxes and class labels for multiple objects in a single pass through the image.</li>
<li><strong>How it works:</strong> YOLO divides the image into a grid and simultaneously predicts bounding boxes and class probabilities for each cell.</li>
<li><strong>Advantages:</strong> Fast, accurate, and suitable for real-time applications such as video analysis, robotics, and surveillance.</li>
<li><strong>Use cases:</strong> Detecting people, vehicles, animals, and everyday objects in images or video frames.</li>
</ul>
<div id="6b32936a" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Object Detection with YOLO</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ultralytics <span class="im">import</span> YOLO</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The YOLO model loaded above (yolo_model) is a pre-trained deep learning object detector from the Ultralytics YOLO family.</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># YOLO ("You Only Look Once") models are designed for real-time object detection in images and videos.</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># They predict bounding boxes and class labels for multiple objects in a single forward pass.</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># The model file 'yolo11n.pt' is a specific version/size of YOLO.</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>yolo_model <span class="op">=</span> YOLO(<span class="st">'yolo11n.pt'</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the first frame of the video file and use it as the image</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>video_path <span class="op">=</span> <span class="st">'GX010881.MP4'</span>  <span class="co"># Change to your video file name if needed</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>cap <span class="op">=</span> cv2.VideoCapture(video_path)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>cap.release()</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> ret:</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> frame</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Run YOLO detection on the first frame</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> yolo_model(img)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    img_detected <span class="op">=</span> img.copy()</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> result <span class="kw">in</span> results:</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> box <span class="kw">in</span> result.boxes:</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>            class_id <span class="op">=</span> <span class="bu">int</span>(box.cls[<span class="dv">0</span>])</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>            confidence <span class="op">=</span> <span class="bu">float</span>(box.conf[<span class="dv">0</span>])</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>            class_name <span class="op">=</span> yolo_model.names[class_id]</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>            x1, y1, x2, y2 <span class="op">=</span> <span class="bu">map</span>(<span class="bu">int</span>, box.xyxy[<span class="dv">0</span>])</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> confidence <span class="op">&gt;</span> <span class="fl">0.2</span>:</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>                cv2.rectangle(img_detected, (x1, y1), (x2, y2), (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>                cv2.putText(img_detected, <span class="ss">f'</span><span class="sc">{</span>class_name<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>confidence<span class="sc">:.2f}</span><span class="ss">'</span>,</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>                            (x1, y1<span class="op">-</span><span class="dv">10</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="fl">0.7</span>, (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    img_detected_rgb <span class="op">=</span> cv2.cvtColor(img_detected, cv2.COLOR_BGR2RGB)</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img_detected_rgb)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'YOLO Object Detection (First Video Frame)'</span>)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    plt.axis(<span class="st">'off'</span>)</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Could not load first frame from video.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="mediapipe-face-detection" class="level4">
<h4 class="anchored" data-anchor-id="mediapipe-face-detection">MediaPipe Face Detection</h4>
<ul>
<li><strong>MediaPipe</strong> is a framework from Google for building cross-platform ML pipelines. Its face detection model is designed for real-time applications and works well on both close-up and wide-angle scenes.</li>
<li><strong>How it works:</strong> The model uses machine learning to find faces and estimate their bounding boxes, returning confidence scores for each detection.</li>
<li><strong>Advantages:</strong> Lightweight, fast, and robust to variations in pose and lighting.</li>
<li><strong>Use cases:</strong> Face tracking, privacy blurring, selfie enhancement, and interactive applications.</li>
</ul>
<div id="6955fb53" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Face Detection with MediaPipe</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mediapipe <span class="im">as</span> mp</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The MediaPipe Face Detection model is a lightweight, real-time face detector from Google.</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># It uses machine learning to find faces and estimate their bounding boxes in images or video frames.</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># The model is fast and works well for both close-up selfies and wider scenes, depending on the model_selection parameter.</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># It outputs detection objects with bounding box coordinates and confidence scores.</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>mp_face_detection <span class="op">=</span> mp.solutions.face_detection</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tip: model_selection=0 is tuned for close-up faces (e.g., selfies); model_selection=1 is for wider scenes.</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tip: increase min_detection_confidence (0.0-1.0) to reduce false positives at the cost of missing faint faces.</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> mp_face_detection.FaceDetection(model_selection<span class="op">=</span><span class="dv">1</span>, min_detection_confidence<span class="op">=</span><span class="fl">0.5</span>) <span class="im">as</span> face_detection:</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        img_rgb <span class="op">=</span> cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        results <span class="op">=</span> face_detection.process(img_rgb)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        img_faces <span class="op">=</span> img_rgb.copy()</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        h_img, w_img <span class="op">=</span> img_faces.shape[:<span class="dv">2</span>]</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> results.detections:</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> detection <span class="kw">in</span> results.detections:</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>                bboxC <span class="op">=</span> detection.location_data.relative_bounding_box</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>                x <span class="op">=</span> <span class="bu">int</span>(bboxC.xmin <span class="op">*</span> w_img)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>                y <span class="op">=</span> <span class="bu">int</span>(bboxC.ymin <span class="op">*</span> h_img)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>                w <span class="op">=</span> <span class="bu">int</span>(bboxC.width <span class="op">*</span> w_img)</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>                h <span class="op">=</span> <span class="bu">int</span>(bboxC.height <span class="op">*</span> h_img)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>                cv2.rectangle(img_faces, (x, y),</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>                              (x <span class="op">+</span> w, y <span class="op">+</span> h), (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>            plt.imshow(img_faces)</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>            plt.title(<span class="st">'MediaPipe Face Detection'</span>)</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>            plt.axis(<span class="st">'off'</span>)</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>            plt.show()</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Note: each detection object has a score (detection.score). You can filter detections by inspecting that value.</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Faces detected: </span><span class="sc">{</span><span class="bu">len</span>(results.detections)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'No faces detected.'</span>)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Image not loaded. Run the first cell.'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</section>
<section id="video-processing-object-and-face-detection-with-privacy-blurring" class="level3">
<h3 class="anchored" data-anchor-id="video-processing-object-and-face-detection-with-privacy-blurring">Video Processing: Object and Face Detection with Privacy Blurring</h3>
<p>The next cell defines and runs a function called <code>process_video</code> that processes a video file frame-by-frame. For each frame, it performs:</p>
<ul>
<li><p><strong>Object Detection (YOLO):</strong><br>
Uses the YOLO model to detect people in the frame and draws green rectangles around them.</p></li>
<li><p><strong>Face Detection (MediaPipe):</strong><br>
Uses MediaPipe to detect faces, draws blue rectangles around each detected face, and applies a blur to the face region for privacy protection.</p></li>
<li><p><strong>Interactive Display:</strong><br>
The processed frames are displayed interactively in the notebook, allowing you to watch the detection and blurring in real time.</p></li>
<li><p><strong>Robust Face Tracking:</strong><br>
If a face is missed in a frame, the function keeps the last known face location for a few frames to maintain privacy blurring even during brief detection failures.</p></li>
</ul>
<p>This workflow demonstrates how to combine deep learning-based object detection and lightweight face detection for privacy-aware video analysis in Python.</p>
<div id="f9d8df52" class="cell" data-execution_count="138">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display, clear_output</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> contextlib</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ultralytics <span class="im">import</span> YOLO</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _get_valid_ksize(fw, fh, base<span class="op">=</span><span class="dv">51</span>):</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    ksize <span class="op">=</span> <span class="bu">min</span>(fw, fh, base)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    ksize <span class="op">=</span> <span class="bu">max</span>(ksize, <span class="dv">3</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ksize <span class="op">%</span> <span class="dv">2</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        ksize <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">int</span>(ksize)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_video(video_path, max_frames<span class="op">=</span><span class="dv">30</span>, max_missed<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    yolo_model <span class="op">=</span> YOLO(<span class="st">'yolo11n.pt'</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    mp_face_detection <span class="op">=</span> mp.solutions.face_detection</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    cap <span class="op">=</span> cv2.VideoCapture(video_path)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    last_face_boxes <span class="op">=</span> []</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    missed_frames <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    frames_shown <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    img_plot <span class="op">=</span> <span class="va">None</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> mp_face_detection.FaceDetection(model_selection<span class="op">=</span><span class="dv">1</span>, min_detection_confidence<span class="op">=</span><span class="fl">0.5</span>) <span class="im">as</span> face_detection:</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> cap.isOpened() <span class="kw">and</span> frames_shown <span class="op">&lt;</span> max_frames:</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>            ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> ret:</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">'End of video or cannot read the frame.'</span>)</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>            <span class="co"># YOLO person detection (suppress output)</span></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> <span class="bu">open</span>(os.devnull, <span class="st">'w'</span>) <span class="im">as</span> fnull, contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>                results <span class="op">=</span> yolo_model(frame, verbose<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> result <span class="kw">in</span> results:</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> box <span class="kw">in</span> result.boxes:</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>                    class_id <span class="op">=</span> <span class="bu">int</span>(box.cls[<span class="dv">0</span>])</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>                    confidence <span class="op">=</span> <span class="bu">float</span>(box.conf[<span class="dv">0</span>])</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>                    class_name <span class="op">=</span> yolo_model.names[class_id]</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>                    x1, y1, x2, y2 <span class="op">=</span> <span class="bu">map</span>(<span class="bu">int</span>, box.xyxy[<span class="dv">0</span>])</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> confidence <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="kw">and</span> class_name <span class="op">==</span> <span class="st">'person'</span>:</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>                        cv2.rectangle(frame, (x1, y1),</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>                                      (x2, y2), (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>                        cv2.putText(frame, <span class="ss">f'Person </span><span class="sc">{</span>confidence<span class="sc">:.2f}</span><span class="ss">'</span>, (</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>                            x1, y1<span class="op">-</span><span class="dv">10</span>), cv2.FONT_HERSHEY_SIMPLEX, <span class="fl">0.7</span>, (<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># MediaPipe face detection</span></span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>            rgb_frame <span class="op">=</span> cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>            results <span class="op">=</span> face_detection.process(rgb_frame)</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>            h_img, w_img <span class="op">=</span> frame.shape[:<span class="dv">2</span>]</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>            current_face_boxes <span class="op">=</span> []</span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> results.detections:</span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> detection <span class="kw">in</span> results.detections:</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>                    bboxC <span class="op">=</span> detection.location_data.relative_bounding_box</span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>                    x <span class="op">=</span> <span class="bu">int</span>(bboxC.xmin <span class="op">*</span> w_img)</span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>                    y <span class="op">=</span> <span class="bu">int</span>(bboxC.ymin <span class="op">*</span> h_img)</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>                    w <span class="op">=</span> <span class="bu">int</span>(bboxC.width <span class="op">*</span> w_img)</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a>                    h <span class="op">=</span> <span class="bu">int</span>(bboxC.height <span class="op">*</span> h_img)</span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>                    x1 <span class="op">=</span> <span class="bu">max</span>(x, <span class="dv">0</span>)</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>                    y1 <span class="op">=</span> <span class="bu">max</span>(y, <span class="dv">0</span>)</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a>                    x2 <span class="op">=</span> <span class="bu">min</span>(x <span class="op">+</span> w, w_img)</span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>                    y2 <span class="op">=</span> <span class="bu">min</span>(y <span class="op">+</span> h, h_img)</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>                    current_face_boxes.append((x1, y1, x2, y2))</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> current_face_boxes:</span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a>                last_face_boxes <span class="op">=</span> current_face_boxes</span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a>                missed_frames <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a>                missed_frames <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Draw blue rectangle, add text, and blur face for each detected face</span></span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> last_face_boxes <span class="kw">and</span> missed_frames <span class="op">&lt;=</span> max_missed:</span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> (x1, y1, x2, y2) <span class="kw">in</span> last_face_boxes:</span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a>                    face_roi <span class="op">=</span> frame[y1:y2, x1:x2]</span>
<span id="cb15-70"><a href="#cb15-70" aria-hidden="true" tabindex="-1"></a>                    fh, fw <span class="op">=</span> face_roi.shape[:<span class="dv">2</span>]</span>
<span id="cb15-71"><a href="#cb15-71" aria-hidden="true" tabindex="-1"></a>                    ksize <span class="op">=</span> _get_valid_ksize(</span>
<span id="cb15-72"><a href="#cb15-72" aria-hidden="true" tabindex="-1"></a>                        fw, fh, base<span class="op">=</span><span class="dv">51</span> <span class="op">+</span> <span class="dv">10</span> <span class="op">*</span> missed_frames)</span>
<span id="cb15-73"><a href="#cb15-73" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> face_roi.size <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> ksize <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb15-74"><a href="#cb15-74" aria-hidden="true" tabindex="-1"></a>                        blurred_face <span class="op">=</span> cv2.GaussianBlur(</span>
<span id="cb15-75"><a href="#cb15-75" aria-hidden="true" tabindex="-1"></a>                            face_roi, (ksize, ksize), <span class="dv">0</span>)</span>
<span id="cb15-76"><a href="#cb15-76" aria-hidden="true" tabindex="-1"></a>                        frame[y1:y2, x1:x2] <span class="op">=</span> blurred_face</span>
<span id="cb15-77"><a href="#cb15-77" aria-hidden="true" tabindex="-1"></a>                        cv2.rectangle(frame, (x1, y1),</span>
<span id="cb15-78"><a href="#cb15-78" aria-hidden="true" tabindex="-1"></a>                                      (x2, y2), (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb15-79"><a href="#cb15-79" aria-hidden="true" tabindex="-1"></a>                        cv2.putText(frame, <span class="st">'Face'</span>, (x1, y1<span class="op">-</span><span class="dv">10</span>),</span>
<span id="cb15-80"><a href="#cb15-80" aria-hidden="true" tabindex="-1"></a>                                    cv2.FONT_HERSHEY_SIMPLEX, <span class="fl">0.7</span>, (<span class="dv">255</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dv">2</span>)</span>
<span id="cb15-81"><a href="#cb15-81" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update the image plot</span></span>
<span id="cb15-82"><a href="#cb15-82" aria-hidden="true" tabindex="-1"></a>            clear_output(wait<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-83"><a href="#cb15-83" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> img_plot <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb15-84"><a href="#cb15-84" aria-hidden="true" tabindex="-1"></a>                img_plot <span class="op">=</span> ax.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))</span>
<span id="cb15-85"><a href="#cb15-85" aria-hidden="true" tabindex="-1"></a>                ax.axis(<span class="st">'off'</span>)</span>
<span id="cb15-86"><a href="#cb15-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb15-87"><a href="#cb15-87" aria-hidden="true" tabindex="-1"></a>                img_plot.set_data(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))</span>
<span id="cb15-88"><a href="#cb15-88" aria-hidden="true" tabindex="-1"></a>                fig.canvas.draw_idle()</span>
<span id="cb15-89"><a href="#cb15-89" aria-hidden="true" tabindex="-1"></a>            display(plt.gcf())</span>
<span id="cb15-90"><a href="#cb15-90" aria-hidden="true" tabindex="-1"></a>            frames_shown <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-91"><a href="#cb15-91" aria-hidden="true" tabindex="-1"></a>    cap.release()</span>
<span id="cb15-92"><a href="#cb15-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-93"><a href="#cb15-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-94"><a href="#cb15-94" aria-hidden="true" tabindex="-1"></a>process_video(<span class="st">'test_video.MP4'</span>)  <span class="co"># Change to your video file name</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="IntroductionImageProcessing_files/figure-html/cell-15-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>